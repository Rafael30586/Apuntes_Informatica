¿Qué es cloud computing? Es la práctica de usar una red de servidores remotos hospedados en internet para almacenar, gestionar y procesar datos, en lugar de hacerlo en una computadora personal o un servidor local.

Evolución del hospedaje en la nube:
- Servidor dedicado: una máquina física dedicada a un solo negocio. Corre una sola aplicación web. Es muy caro, requiere mucho mantenimiento y  es de alta seguridad.
- Servidor privado virtual o VPS: Una máquina física dedicada a un solo negocio. La máquina física es virtualizada en sub máquinas. Corre múltiples aplicaciones web. Mejor utilización y aislamiento de recursos.
- Hospedaje compartido o shared hosting: Una máquina física compartida por cientos de negocios. Muy barato, funcionalidad limitada y pobre aislamiento.
- Hospedaje en la nube o cloud hosting: múltiples máquinas físicas que actúan como un solo sistema. El sistema es abstraído en múltiples servicios en la nube. Es flexible, escalable, seguro, altamente configurable y "cost-effective".

Amazon: es una corporación multinacional americana con su sede en Seattle. Fue fundad en 1994 por Jeff Bezos y comenzó como un atienda en línea de libros y se expandió a otros productos.

AWS: son los servicios de la nube de amazon. Fue lanzado en 2006.

Simple Queue Service o SQS: fue el primer servicio de AWS lanzado al público.

Simple Storage Service o S3: fue lanzado en marzo de 2006.

Elastic Compute Cloud o EC2: lanzado en agosto de 2006.

En 2010 se reportó que los sitios de web de "retail" de amazon.com migraron a AWS.

En abril de 2003 Amazon empezó a ofrecer programas de certificación para ingenieros en computación.

Proveedores de servicios en la nube (CSPs):
- proveen múltiples servicios en la nube, decenas a centenas de servicios;
- esos servicios en la nube pueden ser encadenados entre sí para crear arquitecturas en la nube;
- esos servicios en la nube son accesibles vía una sola API unificada, por ejemplo, AWS API. 
- esos servicios en la nube tienen  una oferta  de infraestructura como un servicio (IaaS).
- esos servicios en la nube utilizan facturación medida basada en uso (por hora, por segundo, etc).
- esos servicios tienen rico monitoreo integrado, ejemplo AWSCLoudTrail
- esos servicios ofrecen automatización vía infraestructura como código (IaC) 
Si una compañía ofrece múltiples servicios en la nube bajo un a misma interfaz de usuario pero no cumple con la mayoría de estos requisitos, estaríamos hablando de una plataforma en la nube o cloud platform, ejemplos: Twilio, HashiCorp, Databricks

CPSs:
- Top tier: AWS, Microsoft Azure, Google Cloud Platform, Alibaba Cloud.
- Mid tier: IBM Cloud, Oracle Cloud, Huawei Cloud, Tencent Cloud.
- Light Tier: Vultr, Digital ocean, Akamai Connected Cloud (Linode).
- Private tier: OpenStack (Rackspace), Apache CloudStack, *Vmware vSphere.

Un proveedor de servicios en la nube puede tener cientos de servicio en la nube que están agrupados en varios tipos de servicios. Los cuatro tipos de servicios cloud más comunes para infraestructura como un servicio (IaaS) serían:
- computar: una computadora virtual en la que puede correr una aplicación, programas y código.
- redes: podría ser una red virtual que defina concexiones de internet o aislamientos de red entre servicios o saliente al internet.
- almacenamiento: podría ser un disco duro virtual que almacena archivos.
- bases de datos: podría ser una base de datos virtual pata guardar datos de reportes o una base de datos para una aplicación web de propósito general.

Evolución de la computación en la nube:
- servidor dedicado:
* un servidor físico utilizado por un cliente.
* tenés que adivinar la capacidad
* se paga de más porque hay mucho que no se utiliza.
* no se puede escalar verticalmente, hace falta una migración manual.
* reemplazar un servidor es muy difícil.
* estás limitado por el sistema operativo huésped.
* múltiples aplicaciones pueden resultar en conflictos al compartir recursos.
* tenés garantía de seguridad, privacidad y completa utilización de recursos subyacentes.
- máquinas virtuales: 
* se puede ejecutar varias máquinas virtuales en una sola máquina física.
* el hypervisor es el software que permite ejecutar las MVs.
* un servidor físico compartido por varios clientes.
* se paga por una fracción del servidor. 
* se paga de más por una máquina virtual porque hay espacio que está sin usar.
* estanos limitados por el sistema operativo huésped.
* varias aplicaciones en una misma máquina virtual pueden resultar en conflictos al compartir recursos.
* es fácil exportar o importar imágenes para la migración.
* es fácil de escalar vertical u horizontalmente.
- contenedores: 
* máquinas virtuales ejecutando varios contenedores.
* Docker Daemon es el nombre de la capa de software que permite ejecutar múltiples contenedores.
* se puede maximizar la utilización de la capacidad disponible lo cual es mejor para el teme del costo.
* los contenedores comparten el mismo sistema operativo subyacente por lo que los contenedores son más eficientes que múltiples máquinas virtuales.
- funciones: 
* son MVs gestionadas ejecutando contenedores gestionados.
* conocido como computación serverless
* subís una pieza de código, elegís la cantidad de memoria y duración.
* solo responsable por el código y los datos.
* muy buen costo, solo pagás por el tiempo en el que el código está en ejecución, las MVs solo están en funcionamiento cuando hay código por ejecutar.

Tipos de computación en la nube:
* SaaS o software as a service: es un producto gestionado por el proveedor de servicio. No nos preocupamos de como el servicio es mantenido. Funciona y se mantiene disponible. Ejemplos: Salesforce, Gmail, office 365. Diseñado para clientes.
* PaaS o platform as a service: se enfoca en el despliegue y gestión de nuestras aplicaciones. No hay que preocuparse por configurar o entender el hardware o el S.O. Ejemplos: Heroku, Elastic beanstalk. Pensados para desarrolladores.
* IaaS o infraestructure as a service: provee acceso a características de redes, computadoras y espacio para almacenar datos. No hay que preocuparse del personal IT, centros de datos y hardware. Ejemplos: Microsoft azure, AWS y Oracle cloud. Pensados para administradores.

Modelos de despliegue en computación en la nube:
* Public cloud: todo está construido sobre el proveedor de servicios en la nube. También conocido como cloud native o cloud first.
* Private cloud: todo está construido sobre datacenters de la compañía. También conocido como on-premise. La nube podría ser OpenStack.
* Híbrido: usa los dos anteriores. Hay una conexión (podría ser VPN) entre el datacenter y el VPC del CSP.
* Cross-cloud: usa múltiples proveedores de la nube.

Casos de uso de los modelos de despliegue en la nube:
* Public cloud: compañías que están empezando ya o que son lo bastante pequeñas como para hacer el paso de VPS a CSP. Startups, ofrecimiento de SaaS,  nuevos proyectos y compañías. Ejemplo: Dropbox.
* Híbrido: Organizaciones que empezaron con su propio datacenter. No pueden moverse completamente a cloud debido a esfuerzo de migración o cumplimiento de seguridad. Bancos, Fintech, grandes proveedores de servicios profesionales.
* On-Premise: organizaciones que no pueden funcionar en cloud debido a cumplimiento de regulación estricto o por el tamaño de su organización. Sector público (gobierno), hospitales con información muy sensible, empresas de seguros.

Beneficios para una empresa que migre a cloud:
* Incrementar velocidad y agilidad.
* Pay-as-you-go pricing: trade capital expense for variable expense.
* Economy of scale: Benefit from massive economies of scale.
* Alcance global en minutos.
* Seguridad.
* Confiabilidad: no hace falta gastar dinero en correr y mantener datacenters.
* Alta disponibilidad.
* Escalabilidad.
* Elasticidad.

Seis ventajas del cloud:
* Cambiá "capital expense" por "variable expense": Pagás on-demand lo que significa que pagás por lo que consumís por horas, por minutos o por segundos.
* Beneficios de economías masivas de escalado: compartís el costo con otros clientes para ahorrar mucho. Cientos de miles de usuarios usando una fracción de un servidor.
* No hace falta adivinar la capacidad: lanzar o destruir servicios cuando queramos en lugar de pagar por servidores sub utilizados.
* Incrementar velocidad y agilidad: lanzar recursos en unos poco minutos con unos pocos clicks.
* No hace falta gastar dinero en ejecutar y mantener datacenters: enfócate en tus propios clientes, desarrollando y configurando tus aplicaciones.
* Volvete global en minutos: desplegá tu aplicación en múltiples regiones alrededor del mundo con unos pocos clicks. Se provee latencia más baja y una mejor experiencia para los clientes a un costo mínimo.

------------------------------------------------------------------------------------------------------
Infraestructura Global De AWS
------------------------------------------------------------------------------------------------------

¿Qué es la infraestructura global de AWS? es hardware y datacenters que están globalmente distribuidos y conectados entre sí para funcionar como un gran recurso para los clientes.
La infraestructura global de AWS está hecha de los siguientes recursos:
* 32 launched regions
* 102 zonas de disponibilidad
* 115 lugares de conexión directa
* más de 550 puntos de presencia
* 35 zonas locales o Lcal zones
* 29 wavelength zones
Ejemplo: en la región de US oeste (Oregon) hay 4 zonas de disponibilidad. 

Regiones: son ubicaciones que consisten en una o más zonas de disponibilidad.
Cada región está físicamente aislada de las otras regiones en términos de ubicación, energía y suministro de agua. 
La primera región fue US-East 1 (Northern Virginia). Casi todos los servicios se hacen disponibles primero en esta región.
El costo de los servicios varían según la región.
Al elegir una región hay cuatro factores a considerar:
* Las regulaciones de la región.
* El costo de los servicios de AWS en la región.
* Qué servicios de AWS están disponibles. 
* Cual es la latencia o distancia con respecto a los usuarios.
No todos los servicios de AWS están disponibles en todas las regiones.

Los servicios de AWS pueden ser globales o regionales.
Los servicios globales operan a través de múltiples regiones y están fijados como globales. Ejemplos: Amazon S3, CloudFront, Route53, IAM. 

Zonas de disponibilidad (availability zones): son ubicaciones físicas para uno o más data centers.
Un datacenter es un edificio que contiene cientas o miles de computadores.
Los datacenters de una región están aislados entre sí (están en diferentes edificios), pero estarán lo suficientemente cerca como para que haya poca latencia (<10ms).
Las zonas de disponibilidad están representadas por un código de región, seguido por una letra, ejemplo: us-east-1a.
Una subred está asociada a una zona de disponibilidad.
Nunca elegimos una zona de disponibilidad al lanzar recursos, lo que hacemos es elegir una subred que está asociada a una AZ (zona de disponibilidad).
Todas las AZs de una región están interconectadas por una fibra dedicada que provee alto rendimiento, con alto ancho de banda, baja latencia, etc.
Todo el tráfico entre las AZs está encriptado.
Las AZs están alejadas unos 100km la una de la otra.

Dominio de fallas o fault domain: es una sección de una red que es vulnerable a daños si un dispositivo crítico o sistema falla. Su propósito es que si un fallo ocurre no irá en cascada fuera del dominio, limitando el daño posible.
Se puede tener dominios de fallas anidados en otros dominios de fallas. 
Un nivel de fallas o fault level es una colección de dominios de fallas.
Una región AWS sería un nivel de fallas y un zona de disponibilidad sería un dominio de fallas.
Cada región de Amazon está completamente aislada de otras regiones de Amazon. Esto produce la máxima estabilidad y tolerancia a fallos posible.
Cada AZ está aislada, pero las AZs de una región están conectadas entre sí mediante enlaces de baja latencia.
Cada AZ está diseñada como una zona de fallos independiente.

Red global de AWS: representa la interconexión entre la infraestructura global de AWS. Comúnmente conocido como la columna vertebral de AWS. Puede pensárselo como una autopista, donde las cosas pueden moverse rápidamente entre datacenters.
VPC endpoints: aseguran que los recursos permanezcan en la red de AWS y no lleguen hasta la internet pública.
Edge locations: pueden funcionar como rampas o como vias de escape a la red global de AWS.
AWS Global Accelerator y AWS S3 Transfer Acceleration: Usa Edge locations para alcanzar recursos de AWS en otras regiones atravesando rápidamente la red global de AWS.
Amazon CloudFront (CDN): Usa Edge locations como una via de escape para proveer al Edge storage y computar cerca del usuario final. 

Edge locations: son integrales a la infraestructura de AWS permitiendo el envío de contenido y aplicaciones con baja latencia y alto rendimiento. Funcionando como datacenters al borde de la red estas ubicaciones cachean contenido, procesan datos y traen los servicios cloud más cerca de los usuarios finales. Son datacenters estratégicamente posicionados alrededor del mundo diseñados para optimizar el envío de contenido y aplicaciones. Funcionan como puntos de presencia para los servicios de AWS permitiendo que los datos sean servidos desde la ubicación más cercana al usuario final lo cual reduce significativamente la latencia.

https://www.geeksforgeeks.org/devops/aws-edge-locations/

Puntos de presencia o PoP (points of presence): es una ubicación intermedia entre una región de AWS y el usuario final. Esta ubicación podría ser un datacenter o una colección de hardware.
Para AWS un PoP es un datacenter poseído por AWS o un socio de confianza que es utilizado por servicios de AWS relacionados por envío de contenido o subida acelerada (expediated upload).
Edge locations: son datacenters que guardan cache de los archivos más populares (páginas web, imágenes y videos) para que el envío a distancia a los usuarios finales se reduzca.
Regional Edge locations: son datacenters que guardan caches mucho más grandes de archivos menos populares para reducir el costo y la tarifa de transferencia.

https://docs.aws.amazon.com/whitepapers/latest/aws-fault-isolation-boundaries/points-of-presence.html

Redes de tier 1: es una red que puede alcanzar cualquier otra red en internet sin comprar tránsito de IP o pagar por "peering".
Las AZs de AWS están todas conectadas de manera redundante a múltiples proveedores de tránsito tier-1.

Servicios de AWS que usan PoPs para envío de contenido o subida acelerada:
* Amazon CloudFront. Es un CDN. Apuntás tu sitio web a CloudFront para que encamine las solicitudes a la cache de la edge location más cercana.
Te permite elegir un origen (como un servidor web) que será la fuente de lo cacheado.
Cachea el contenido de lo que retorna el origen a varias edge locations alrededor del mundo.
* Amazon S3 transfer acceleration: permite generar un URL especial que puede ser usada por usuarios finales para subir archivos a una edge location cercana. Una vez que un archivo es subido a una edge location, puede moverse mucho más rápido en la red de AWS para alcanzar S3.
* AWS global accelerator: puede encontrar el camino óptimo desde un usuario a tus servidores web. Global accelerator son desplegados en edge locations para que puedas tráfico de usuario a una edge location en lugar de hacerlo directamente a tu aplicación web.

AWS direct connect
Es una conexión privada/dedicada entre tu datacenter, oficina, co-ubicación y AWS.
¿Qué es una co-ubicación o co-location? es un datacenter donde el equipamiento, el espacio y  el ancho de banda está disponible para alquiler para clientes minoristas.
Tiene dos opciones de conexión de red muy rápidas:
* Ancho de banda más bajo: 50MBps-500MBps
* Ancho de banda más alto: 1GBps-10GBps
Ayuda a reducir costos de red e incrementa el rendimiento del ancho de banda.
Provee una experiencia de red más consistente que una típica conexión a internet (confiable y segura).

Direct Connect Locations
Son datacenters confiables asociados a los cuales podés establecer una conexión dedicada de alta velocidad y baja latencia desde tu "on-premise" a AWS.
Tendrías que usar AWS direct connect para establecer una conexión.

Local Zones
Son datacenters ubicados cerca de áreas densamente pobladas para proveer rendimiento de muy baja latencia para esa área (milisegundos de un dígito de latencia como, por ejemplo 7ms).
Los Angeles California fue la primera Local zone en ser desplegada.
Solo algunos servicios específicos se han hecho disponibles:
* Instancias tipo EC2 (T3, C5, R5, R5d, I3en, G4)
* EBS (io1 y gp2)
* Amazon FSx
* Application Load Balancer
* Amazon VPC
El propósito de las Local zones es apoyar aplicaciones de alta demanda sensibles a latencias:
* Medios y entretenimiento
* Automatoizaciòn de diseño electrónico
* Ad-tech
* Machine learning

WaveLength zones
Permiten "edge-computing" en redes 5G.
Las aplicaciones tendrán ultra baja latencia.
AWS se ha asociado con varias comapañìas para utilizar redes 5G (Verizon, Vodafone, SK telecom, etc).
Creàs una subred atada a una weblength zone y luego podès lanzar máquinas virtuales al borde de las redes 5G objetivo.

Data residency o residencia de datos
Es la ubicación geográfica en donde residen los recursos de una organización o nube.
Compliance boundaries o lìmites de cumplimiento: es un requerimiento legal por un gobierno u organización que describe a donde se les permite residir a los datos y recursos de la nube.
Soberanìa de datos: es el control jurisdiccional o autoridad legal que puede ser afirmada sobre datos porque su ubicación física se encuentra en límites jurisdiccionales.
Para cargas de traqbajo que necesitan cumplir con los lìmites de cumplimiento estrictamente definiendo la residencia de datos y recursos de la nube en AWS se puede usar:
* AWS config es una política como servicio de código. Podès crear reglas para revisar continuamente la configuración de los recursos de AWS.
* AWS outposts es un estante físico de servidores que podès poner en tu datacenter. Tus datos van a residir en donde resida fìsicamente tu outpost.
* IAM policies  

AWS puede utilizarse para el sector público u organizaciones desarrollando cargas de trabajo en la nube para el sector público.
AWS logra esto por programas de cumplimiento regulatorio junto con controles de seguridad y gobernanza. 
AWS tiene regiones especiales para regulaciones de Estados Unidos llamadas GovCloud. 

AWS China
Està completamente aislado intencionalmente de AWS global para cumplir con las regulaciones de China. AWS està en su propio dominio: amazonaws.cn.
Para poder operar en la región de AWS China necesitàs una "China Business License".
No todos los servicios estàsn disponibles en China, por ejemplo: Route53.
AWS tiene dos regiones en China: 
* Ningxia CN-NorthWest-1, manejado por NSWCF
* Beijing CN-North-1, manejado por SINNET

AWS Ground Station
Es un servicio completamente gestionado que te permite controlar comunicaciones satelitales, procesar datos y escalar tus operaciones sin tener que preocuparte por construir o gestionar tu propia infraestructura de estación terrestre.
Casos de uso:
* Pronóstico del clima
* Imágenes de la superficie
* Comunicaciones
* Transmisión de video

AWS Outposts
Es un servicio completamente gestionado que ofrece la misma infraestructura, servicios AWS , API y herramientas para cualquier datacenter, co-ubicación o instalación "on-premise" para una experiencia híbrida consistente.
AWS outposts es un estante de servidores ejecutando infraestructura de AWS en tu ubicación física.
Un estante de servidores es un marco diseñado para organizar equipo IT, ejemplo 42U Rack. La U es por "rack units" o "U spaces" que es igual a 1.75 pulgadas. El estándar de la industria es 48U, que serían siete pies.
Ejemplo de un rack server o estante de servidores: https://media.datacenterdynamics.com/media/images/op_rack_400w_1.original.jpg 

---------------------------------------------------------------------------------------------------
Cloud architecture o arquitectura en la nube
---------------------------------------------------------------------------------------------------

¿Qué es un "solutions architect"?
Es un rol en una organización técnica que diseña una solución técnica usando múltiples sistemas vía búsqueda, documentación y experimentación.
¿Qué es un "cloud architect"?
Es un solutions archictect que está enfocado únicamente en soluciones técnicas arquitectónicas usando servicios cloud.
Un cloud architect necesita entender los siguientes términos y factorizarlos en su arquitectura basado en los requerimientos del negocio:
* Disponibilidad: la habilidad para asegurar que el servicio esté disponible.
* Escalabilidad: la habilidad pata crecer rápido o sin obstáculos.
* Elasticidad: la habilidad para creecer o encogerse para cumplir con la demanda.
* Tolerancia a fallos: la habilidad para prevenir fallos.
* Recuperación de desastre: la habilidad para recuperarse de los fallos.
Un solutions architect necesita siempre considerar los siguinetes factores de negocio:
* Seguridad: cuan segura es la solución.
* Costo: cuanto va a costar.

Alta disponibilidad
Es la habilidad de que un servicio permanezca disponible asegurando que no hayan ningún punto de fallos y asegurar cierto nivel de desampeño.
Asegurar tus cargas de trabajo a través de múltiples AZs asegura que si una o dos AZs dejan de estar disponibles, el servicio o aplicaciones permanezca disponible.
Elastic Load Balancer: Un load balancer o balanceador de carga permite distribuir el tráfico a múltiples servidores en uno o más datacenter. Si un datacenter o servidor deja de estar disponible, el load balancer va a enrutar el tráfico solo a datacenters disponibles con servidores.

Alta escalabilidad
Es la habilidad para incrementar la capacidad basado en el incremento de la demanda de tráfico, memoria y poder de cómputo.
* Escalado vertical (scaling up): mejorar a un servidor más grande.
* Escalado horizontal (scaling out): añadir más servidores del mismo tamaño. 

Alta elasticidad
Es la habilidad para incrementar o decrementar automáticamente la capacidad basado en el tráfico actual, memoria y poder de cómputo. Se suele confundir con alta escalabilidad.
Escalado hotizontal:
* Scaling out: añadir más servidores del mismo tamaño.
* Scaling in: quitar servidores poco utilizados del mismo tamaño.
El escalado vertical es generalmente difícil para la arquitectura tradicional por lo que generalmente verás solamente escalado hotrizontal descrito con elasticidad.
Auto Scaling Groups (ASG): Es una característica de AWS que añadirá automáticamente o quitará servidores basado en regalas de escalado que definís basado en métricas.

Tolerancia a fallos
Es la habilidad de tu servicio de asegurar que no haya ningún punto de fallo.
Fail-over: es cuando tenés que planear cambiar el tráfico a un sistema redundante en caso de que el sistema principal falle. Un ejemplo común es tener una copia de tu base de datos en donde los cambios realizados se sincronizan. El sistema secundario no está en uso hasta que ocurre un "fail-over" y se vuelve la base de datos principal.
RDS Multi-AZ es cuando "corrés" una base de datos duplicada en stand by en otra zona de disponibilidad en caso de que tu base de datos principal falle.

Alta durabilidad 
Es la habilidad para recuperarse de un desastre y prevenir la pérdida de datos. Las soluciones que recuperan de un desastre se conocen como "disaster recovery" (DR)
* ¿Tenés un backup?
* ¿Qué ten rápido podés recuperar ese backup?
* ¿Tu backup todavía funciona?
* ¿Cómo te asegurás de que los datos actuales no está corruptos?
CloudEndure Disaster Recovery replica continuamente tus máquinas a áreas de "staging" de bajo costo en tu cuenta objetivo de AWS y región preferida posibilitando una recuperación rápida y confiable en caso de fallos en el datacenter.

Business continuity plan (BCP)
Es un documento que describe como un negocio continuará operando durante una ruptura no planeada de los servicios.
* Recovery Point Objective (RPO): Es el máximo aceptable de pérdida de datos después de un incidente no planificado, expresado como una cantidad de tiempo.
* Recovery Time Objective (RTO): Es el máximo tiempo de inactividad que tu negocio puede tolerar sin incurrir en una pérdida financiera significativa.

Hay múltiples opciones para recuperación que cambian costo vs tiempo para recuperar.
* Backup y recuperación: se hace un backup de tus datos a una nueva infraestructura. RPO/RTO -> horas.
* "Pilot light": Los datos son replicados a otra región con los mínimos servicios ejecutándose. RPO/RTO -> 10 minutos.
* "Warm standby": copia escalada para abajo de tu infraestructura ejecutándose lista para escalar para arriba. RPO/RTO -> minutos.
* "Multi-site Active/active": copia escalada para arriba de tu infraestructura en otra región. RPO/RTO -> tiempo real. 

https://media.geeksforgeeks.org/wp-content/uploads/20250419125835918183/AWS-Disaster-Recovery.webp

Recovery time objective (RTO): es el máximo retraso aceptable entre la interrupción del servicio y la recuperación del mismo. Este objetivo determina la que es considerada una ventana aceptable de tiempo cuando el servicio no está disponible y es definido por la organización.

Recovery point objective (RPO): Es la máxima cantidad de tiempo aceptable desde el último punto de recuperación de datos. Este objetivo determina lo que es considerado una aceptable pérdida de datos entre el último punto de recuperación y la interrupción del servicio y es definido por la organización.
  
------------------------------------------------------------------------------------------------------
Herramientas de gestión y desarrollo
------------------------------------------------------------------------------------------------------
API de AWS
Una API es un software que permite que dos aplicaciones o servicios se comuniquen entre sí. El tipo más común es vía solicitudes HTTP/S
La API de AWS es una API HTTP con la cual se puede interactuar enviando solicitudes HTTP usando aplicaciones como Postman.
Cada servicio de AWS tiene su propio endpoint al cual podés enviarle solicitudes.
Es raro que los usuarios envíen solicitudes directamente a la API de AWS. Es mucho más fácil interactuar con la API usando herramientas de desarrollador: AWS management console; AWS SDK, interactuá con la API usando tu lenguaje de programación favorito; AWS CLI, interactuá con la API usando una Shell/terminal. 

AWS management console
Es una consola unificada basada en web. Permite construir, gestionar y monitorear todo desde simples aplicaciones web hasta complejos despliegues en la nube.
Permite apuntar y clickear para configurar manualmente recursos de AWS con conocimiento limitado sobre programación.
A esto se le conoce como ClickOps, ya que podés llevar a cabo todas tus operaciones de sistema vía clicks.   

https://res.cloudinary.com/hy4kyit2a/f_auto,fl_lossy,q_70/learn/modules/aws-cloud/use-the-aws-management-interfaces/images/35f42a4e069a9142d9edf235ad7d732e_ck-2-kwnd-9-i-003-s-0-y-5-jhiwbea-4-r.png
- imagen de AWS console

Service console
Cada servicio de AWS tiene su propia consola personalizada. Podés acceder a estas consolas buscando el nombre del servicio.
Algunas consolas de servicio de AWS se comportarán como paraguas conteniendo muchos servicios de AWS, ejemplos: VPC console, EC2 console, Systems manager console, SageMaker console, CloudWatch console.  

ID de cuenta de AWS
Toda cuenta de AWS tiene un ID único. Está compuesto de 12 dígitos, ejemplo: 271940387265. Se usa cuando ingresamos con un usuario que no sea root y tiene otros usos también (Cross-account roles, support cases, etc). 
Generalmente es buena idea mantener el ID en secreto, ya que es uno de los datos que puede usar alguien malicioso para atacar.


AWS tools for Powershell
¿Qué es powershell? es una Shell de línea de comandos y lenguaje de scripting. A diferencia de la mayoría de las shells, que aceptan devuelven texto, powershell está construida sobre el entorno de ejecución .NET y acepta y devuelve objetos .NET. 
AWS tolos for powershell Te permite interactuar con la api de AWS vía cdmlets de powershell.
Los cmdlets son tipos especiales de comandos de powershell.

Amazon resource names o ARNs
Identifican recursos de AWS. Los ARNs son requeridos para especificar un recurso sin ambigüedades por todo AWS. 
Los ARN pueden tener los siguientes formatos:
* arn:partition:service:region:account-id:resource-id
* arn:partition:service:region:account-id:resource-type/resource-id
* arn:partition:service:region:account-id:resource-type:resource-id
Ejemplos de las partes de un ARN:
* Partition
- aws -> Regiones de aws
- aws-cn -> Región de China
- aws-us-gov -> Región AWS GovCloud (EEUU)
* Service - identifica al servicio
- ec2
- s3
- iam
* Región - cual recurso de AWS
- us-east-1
- ca-central
* Account id
- 374102816883
- 183092871115
* Resource id - puede ser un número, nombre o ruta
- user/Bob
- instance/i-1234567890abcdef0
En la AWS mangement console es común tener la posibilidad de copiar el ARN al clipboard.

AWS CLI
¿Qué es una CLI? procesa comandos a un programa de computadora en la forma de líneas de texto. Los sistemas operativos implementan una CLI en una shell.
¿Qué es una terminal? es una interface de solo texto.
¿Qué es una consola? es una computadora física que permitirá la entrada de información en una terminal.
¿Qué es una Shell? es un programa de línea de comandos con el cual los usuarios interactúan al ingresar comandos.
AWS CLI: permite a los usuarios interactuar con la API de AWS vía comandos en una Shell o terminal.
El CLI de AWS es un ejecutable programado en Python, por lo que hace falta tener Python instalado. El nombre del programa es aws y puede ser instalado en Windows, mac o Linux.