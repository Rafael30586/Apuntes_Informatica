¿Qué es cloud computing? Es la práctica de usar una red de servidores remotos hospedados en internet para almacenar, gestionar y procesar datos, en lugar de hacerlo en una computadora personal o un servidor local.

Evolución del hospedaje en la nube:
- Servidor dedicado: una máquina física dedicada a un solo negocio. Corre una sola aplicación web. Es muy caro, requiere mucho mantenimiento y  es de alta seguridad.
- Servidor privado virtual o VPS: Una máquina física dedicada a un solo negocio. La máquina física es virtualizada en sub máquinas. Corre múltiples aplicaciones web. Mejor utilización y aislamiento de recursos.
- Hospedaje compartido o shared hosting: Una máquina física compartida por cientos de negocios. Muy barato, funcionalidad limitada y pobre aislamiento.
- Hospedaje en la nube o cloud hosting: múltiples máquinas físicas que actúan como un solo sistema. El sistema es abstraído en múltiples servicios en la nube. Es flexible, escalable, seguro, altamente configurable y "cost-effective".

Amazon: es una corporación multinacional americana con su sede en Seattle. Fue fundad en 1994 por Jeff Bezos y comenzó como un atienda en línea de libros y se expandió a otros productos.

AWS: son los servicios de la nube de amazon. Fue lanzado en 2006.

Simple Queue Service o SQS: fue el primer servicio de AWS lanzado al público.

Simple Storage Service o S3: fue lanzado en marzo de 2006.

Elastic Compute Cloud o EC2: lanzado en agosto de 2006.

En 2010 se reportó que los sitios de web de "retail" de amazon.com migraron a AWS.

En abril de 2003 Amazon empezó a ofrecer programas de certificación para ingenieros en computación.

Proveedores de servicios en la nube (CSPs):
- proveen múltiples servicios en la nube, decenas a centenas de servicios;
- esos servicios en la nube pueden ser encadenados entre sí para crear arquitecturas en la nube;
- esos servicios en la nube son accesibles vía una sola API unificada, por ejemplo, AWS API. 
- esos servicios en la nube tienen  una oferta  de infraestructura como un servicio (IaaS).
- esos servicios en la nube utilizan facturación medida basada en uso (por hora, por segundo, etc).
- esos servicios tienen rico monitoreo integrado, ejemplo AWSCLoudTrail
- esos servicios ofrecen automatización vía infraestructura como código (IaC) 
Si una compañía ofrece múltiples servicios en la nube bajo un a misma interfaz de usuario pero no cumple con la mayoría de estos requisitos, estaríamos hablando de una plataforma en la nube o cloud platform, ejemplos: Twilio, HashiCorp, Databricks

CPSs:
- Top tier: AWS, Microsoft Azure, Google Cloud Platform, Alibaba Cloud.
- Mid tier: IBM Cloud, Oracle Cloud, Huawei Cloud, Tencent Cloud.
- Light Tier: Vultr, Digital ocean, Akamai Connected Cloud (Linode).
- Private tier: OpenStack (Rackspace), Apache CloudStack, *Vmware vSphere.

Un proveedor de servicios en la nube puede tener cientos de servicio en la nube que están agrupados en varios tipos de servicios. Los cuatro tipos de servicios cloud más comunes para infraestructura como un servicio (IaaS) serían:
- computar: una computadora virtual en la que puede correr una aplicación, programas y código.
- redes: podría ser una red virtual que defina concexiones de internet o aislamientos de red entre servicios o saliente al internet.
- almacenamiento: podría ser un disco duro virtual que almacena archivos.
- bases de datos: podría ser una base de datos virtual pata guardar datos de reportes o una base de datos para una aplicación web de propósito general.

Evolución de la computación en la nube:
- servidor dedicado:
* un servidor físico utilizado por un cliente.
* tenés que adivinar la capacidad
* se paga de más porque hay mucho que no se utiliza.
* no se puede escalar verticalmente, hace falta una migración manual.
* reemplazar un servidor es muy difícil.
* estás limitado por el sistema operativo huésped.
* múltiples aplicaciones pueden resultar en conflictos al compartir recursos.
* tenés garantía de seguridad, privacidad y completa utilización de recursos subyacentes.
- máquinas virtuales: 
* se puede ejecutar varias máquinas virtuales en una sola máquina física.
* el hypervisor es el software que permite ejecutar las MVs.
* un servidor físico compartido por varios clientes.
* se paga por una fracción del servidor. 
* se paga de más por una máquina virtual porque hay espacio que está sin usar.
* estanos limitados por el sistema operativo huésped.
* varias aplicaciones en una misma máquina virtual pueden resultar en conflictos al compartir recursos.
* es fácil exportar o importar imágenes para la migración.
* es fácil de escalar vertical u horizontalmente.
- contenedores: 
* máquinas virtuales ejecutando varios contenedores.
* Docker Daemon es el nombre de la capa de software que permite ejecutar múltiples contenedores.
* se puede maximizar la utilización de la capacidad disponible lo cual es mejor para el teme del costo.
* los contenedores comparten el mismo sistema operativo subyacente por lo que los contenedores son más eficientes que múltiples máquinas virtuales.
- funciones: 
* son MVs gestionadas ejecutando contenedores gestionados.
* conocido como computación serverless
* subís una pieza de código, elegís la cantidad de memoria y duración.
* solo responsable por el código y los datos.
* muy buen costo, solo pagás por el tiempo en el que el código está en ejecución, las MVs solo están en funcionamiento cuando hay código por ejecutar.

Tipos de computación en la nube:
* SaaS o software as a service: es un producto gestionado por el proveedor de servicio. No nos preocupamos de como el servicio es mantenido. Funciona y se mantiene disponible. Ejemplos: Salesforce, Gmail, office 365. Diseñado para clientes.
* PaaS o platform as a service: se enfoca en el despliegue y gestión de nuestras aplicaciones. No hay que preocuparse por configurar o entender el hardware o el S.O. Ejemplos: Heroku, Elastic beanstalk. Pensados para desarrolladores.
* IaaS o infraestructure as a service: provee acceso a características de redes, computadoras y espacio para almacenar datos. No hay que preocuparse del personal IT, centros de datos y hardware. Ejemplos: Microsoft azure, AWS y Oracle cloud. Pensados para administradores.

Modelos de despliegue en computación en la nube:
* Public cloud: todo está construido sobre el proveedor de servicios en la nube. También conocido como cloud native o cloud first.
* Private cloud: todo está construido sobre datacenters de la compañía. También conocido como on-premise. La nube podría ser OpenStack.
* Híbrido: usa los dos anteriores. Hay una conexión (podría ser VPN) entre el datacenter y el VPC del CSP.
* Cross-cloud: usa múltiples proveedores de la nube.

Casos de uso de los modelos de despliegue en la nube:
* Public cloud: compañías que están empezando ya o que son lo bastante pequeñas como para hacer el paso de VPS a CSP. Startups, ofrecimiento de SaaS,  nuevos proyectos y compañías. Ejemplo: Dropbox.
* Híbrido: Organizaciones que empezaron con su propio datacenter. No pueden moverse completamente a cloud debido a esfuerzo de migración o cumplimiento de seguridad. Bancos, Fintech, grandes proveedores de servicios profesionales.
* On-Premise: organizaciones que no pueden funcionar en cloud debido a cumplimiento de regulación estricto o por el tamaño de su organización. Sector público (gobierno), hospitales con información muy sensible, empresas de seguros.

Beneficios para una empresa que migre a cloud:
* Incrementar velocidad y agilidad.
* Pay-as-you-go pricing: trade capital expense for variable expense.
* Economy of scale: Benefit from massive economies of scale.
* Alcance global en minutos.
* Seguridad.
* Confiabilidad: no hace falta gastar dinero en correr y mantener datacenters.
* Alta disponibilidad.
* Escalabilidad.
* Elasticidad.

Seis ventajas del cloud:
* Cambiá "capital expense" por "variable expense": Pagás on-demand lo que significa que pagás por lo que consumís por horas, por minutos o por segundos.
* Beneficios de economías masivas de escalado: compartís el costo con otros clientes para ahorrar mucho. Cientos de miles de usuarios usando una fracción de un servidor.
* No hace falta adivinar la capacidad: lanzar o destruir servicios cuando queramos en lugar de pagar por servidores sub utilizados.
* Incrementar velocidad y agilidad: lanzar recursos en unos poco minutos con unos pocos clicks.
* No hace falta gastar dinero en ejecutar y mantener datacenters: enfócate en tus propios clientes, desarrollando y configurando tus aplicaciones.
* Volvete global en minutos: desplegá tu aplicación en múltiples regiones alrededor del mundo con unos pocos clicks. Se provee latencia más baja y una mejor experiencia para los clientes a un costo mínimo.


¿Qué es la infraestructura global de AWS? es hardware y datacenters que están globalmente distribuidos y conectados entre sí para funcionar como un gran recurso para los clientes.
La infraestructura global de AWS está hecha de los siguientes recursos:
* 32 launched regions
* 102 zonas de disponibilidad
* 115 lugares de conexión directa
* más de 550 puntos de presencia
* 35 zonas locales
* 29 wavelength zones
Ejemplo: en la región de US oeste (Oregon) hay 4 zonas de disponibilidad. 

Regiones: son ubicaciones que consisten en una o más zonas de disponibilidad.
Cada región está físicamente aislada de las otras regiones en términos de ubicación, energía y suministro de agua. 
La primera región fue US-East 1 (Northern Virginia). Casi todos los servicios se hacen disponibles primero en esta región.
El costo de los servicios varían según la región.
Al elegir una región hay cuatro factores a considerar:
* Las regulaciones de la región.
* El costo de los servicios de AWS en la región.
* Qué servicios de AWS están disponibles. 
* Cual es la latencia o distancia con respecto a los usuarios.
No todos los servicios de AWS están disponibles en todas las regiones.

Los servicios de AWS pueden ser globales o regionales.
Los servicios globales operan a través de múltiples regiones y están fijados como globales. Ejemplos: Amazon S3, CloudFront, Route53, IAM. 

Zonas de disponibilidad: son ubicaciones físicas para uno o más data centers.
Un datacenter es un edificio que contiene cientas o miles de computadores.
Los datacenters de una región están aislados entre sí (están en diferentes edificios), pero estarán lo suficientemente cerca como para que haya poca latencia (<10ms).
Las zonas de disponibilidad están representadas por un código de región, seguido por una letra, ejemplo: us-east-1a.
Una subred está asociada a una zona de disponibilidad.
Nunca elegimos una zona de disponibilidad al lanzar recursos, lo que hacemos es elegir una subred que está asociada a una AZ (zona de disponibilidad).
Todas las AZs de una región están interconectadas por una fibra dedicada que provee alto rendimiento, con alto ancho de banda, baja latencia, etc.
Todo el tráfico entre las AZs está encriptado.
Las AZs están alejadas unos 100km la una de la otra.

Dominio de fallas o fault domain: es una sección de una red que es vulnerable a daños si un dispositivo crítico o sistema falla. Su propósito es que si un fallo ocurre no irá en cascada fuera del dominio, limitando el daño posible.
Se puede tener dominios de fallas anidados en otros dominios de fallas. 
Un nivel de fallas o fault level es una colección de dominios de fallas.
Una región AWS sería un nivel de fallas y un zona de disponibilidad sería un dominio de fallas.
Cada región de Amazon está completamente aislada de otras regiones de Amazon. Esto produce la máxima estabilidad y tolerancia a fallos posible.
Cada AZ está aislada, pero las AZs de una región están conectadas entre sí mediante enlaces de baja latencia.
Cada AZ está diseñada como una zona de fallos independiente.

Red global de AWS: representa la interconexión entre la infraestructura global de AWS. Comúnmente conocido como la columna vertebral de AWS. Puede pensárselo como una autopista, donde las cosas pueden moverse rápidamente entre datacenters.
VPC endpoints: aseguran que los recursos permanezcan en la red de AWS y no lleguen hasta la internet pública.
Edge locations: pueden funcionar como rampas o como vias de escape a la red global de AWS.
AWS Global Accelerator y AWS S3 Transfer Acceleration: Usa Edge locations para alcanzar recursos de AWS en otras regiones atravesando rápidamente la red global de AWS.
Amazon CloudFront (CDN): Usa Edge locations como una via de escape para proveer al Edge storage y computar cerca del usuario final. 

Puntos de presencia o PoP: es una ubicación intermedia entre una región de AWS y el usuario final. Esta ubicación podría ser un datacenter o una colección de hardware.
Para AWS un PoP es un datacenter poseído por AWS o un socio de confianza que es utilizado por servicios de AWS relacionados por envío de contenido o subida acelerada (expediated upload).
Edge locations: son datacenters que guardan cache de los archivos más populares (páginas web, imágenes y videos) para que el envío a distancia a los usuarios finales se reduzca.
Regional Edge locations: son datacenters que guardan caches mucho más grandes de archivos menos populares para reducir el costo y la tarifa de transferencia.

Redes de tier 1: es una red que puede alcanzar cualquier otra red en internet sin comprar tránsito de IP o pagar por "peering".
Las AZs de AWS están todas conectadas de manera redundante a múltiples proveedores de tránsito tier-1.
